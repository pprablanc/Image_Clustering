{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tensorflow/Keras imports\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, UpSampling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "raw_data_directory = os.path.join(path, 'Raw_data')\n",
    "list_filename = os.listdir(raw_data_directory)\n",
    "list_filename_full = [os.path.join(path, 'Raw_data', f) for f in list_filename]\n",
    "\n",
    "WIDTH = 128\n",
    "HEIGHT = 192\n",
    "NCHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(f, width=128, height=192):\n",
    "    im = load_img(f, color_mode='rgb', target_size = (width,height))\n",
    "    im_array = img_to_array(im)\n",
    "    im_array = im_array.astype('float32') / 255. \n",
    "    #im_array_x = preprocess_input(im_array)\n",
    "    return im_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load images with parallel processing\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "images = pool.starmap(load_images, [(f, WIDTH, HEIGHT) for f in list_filename_full])\n",
    "images = np.array(images)\n",
    "pool.close()\n",
    "\n",
    "# Split train and validation test\n",
    "x_train, x_test = train_test_split(images, test_size=0.2, random_state=123)\n",
    "#print(x_train.shape)\n",
    "#print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = Input(shape=(WIDTH, HEIGHT, NCHANNELS))\n",
    "\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='./CNN/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 4\n",
    "plt.figure(figsize=(8, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(WIDTH, HEIGHT, NCHANNELS))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(WIDTH, HEIGHT, NCHANNELS))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "\n",
    "# DNN\n",
    "encoder = Model(input_img, encoded)\n",
    "DNN_features = encoder.predict(images)\n",
    "DNN_features = DNN_features.reshape(len(images), -1)\n",
    "DNN_features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "images_vectorized = np.array(images.reshape(len(images), -1))\n",
    "pca = PCA(n_components=0.8)\n",
    "PCA_features = pca.fit_transform(images_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "N_CLUSTERS = 10\n",
    "\n",
    "# Kmeans\n",
    "\n",
    "clf_kmeans_DNN = make_pipeline(preprocessing.StandardScaler(), KMeans(n_clusters=N_CLUSTERS, random_state=0))\n",
    "clf_kmeans_DNN.fit(DNN_features)\n",
    "colors = [str(elt) for elt in clf_kmeans_DNN['kmeans'].labels_]\n",
    "Ydf_DNN = pd.DataFrame(DNN_features[:,0:2])\n",
    "Ydf_DNN['class'] = colors\n",
    "Ydf_DNN['id'] = list_filename\n",
    "Ydf_DNN.columns = ['0', '1', 'class', 'id']\n",
    "\n",
    "\n",
    "# Les données sont centrées/réduites\n",
    "clf_kmeans_PCA = make_pipeline(preprocessing.StandardScaler(), KMeans(n_clusters=N_CLUSTERS, random_state=0))\n",
    "clf_kmeans_PCA.fit(PCA_features)\n",
    "colors = [str(elt) for elt in clf_kmeans_PCA['kmeans'].labels_]\n",
    "Ydf_PCA = pd.DataFrame(PCA_features[:,0:2])\n",
    "Ydf_PCA['class'] = colors\n",
    "Ydf_PCA['id'] = list_filename\n",
    "Ydf_PCA.columns = ['0', '1', 'class', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# T-SNE\n",
    "\n",
    "DNN_TSNE_features = TSNE(n_components=2).fit_transform(DNN_features)\n",
    "clf_kmeans_DNN_TSNE = make_pipeline(preprocessing.StandardScaler(), KMeans(n_clusters=N_CLUSTERS, random_state=0))\n",
    "clf_kmeans_DNN_TSNE.fit(DNN_TSNE_features)\n",
    "colors = [str(elt) for elt in clf_kmeans_DNN_TSNE['kmeans'].labels_]\n",
    "Ydf_DNN_TSNE = pd.DataFrame(DNN_TSNE_features[:,0:2])\n",
    "Ydf_DNN_TSNE['class'] = colors\n",
    "Ydf_DNN_TSNE['id'] = list_filename\n",
    "Ydf_DNN_TSNE.columns = ['0', '1', 'class', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bokeh.plotting as bpl\n",
    "import bokeh.models as bmo\n",
    "from bokeh.palettes import d3\n",
    "bpl.output_file(\"line.html\")\n",
    "\n",
    "source = bpl.ColumnDataSource.from_df(Ydf_DNN)\n",
    "\n",
    "# use whatever palette you want...\n",
    "palette = d3['Category10'][len(Ydf_DNN['class'].unique())]\n",
    "color_map = bmo.CategoricalColorMapper(factors=Ydf_DNN['class'].unique(), \n",
    "                                       palette=palette)\n",
    "\n",
    "# create figure and plot\n",
    "p = bpl.figure(plot_width=1400, plot_height=1000)\n",
    "p.scatter(x='0', y='1',\n",
    "          color={'field': 'class', 'transform': color_map},\n",
    "          legend_label='class', source=source)\n",
    "p.title.text = \"DNN\"\n",
    "bpl.show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpl.output_file(\"line2.html\")\n",
    "\n",
    "source = bpl.ColumnDataSource.from_df(Ydf_PCA)\n",
    "\n",
    "# use whatever palette you want...\n",
    "palette = d3['Category10'][len(Ydf_PCA['class'].unique())]\n",
    "color_map = bmo.CategoricalColorMapper(factors=Ydf_PCA['class'].unique(), \n",
    "                                       palette=palette)\n",
    "\n",
    "# create figure and plot\n",
    "p = bpl.figure(plot_width=1400, plot_height=1000)\n",
    "p.scatter(x='0', y='1',\n",
    "          color={'field': 'class', 'transform': color_map},\n",
    "          legend_label='class', source=source)\n",
    "p.title.text = \"PCA\"\n",
    "bpl.show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpl.output_file(\"line3.html\")\n",
    "\n",
    "source = bpl.ColumnDataSource.from_df(Ydf_DNN_TSNE)\n",
    "\n",
    "# use whatever palette you want...\n",
    "palette = d3['Category10'][len(Ydf_DNN_TSNE['class'].unique())]\n",
    "color_map = bmo.CategoricalColorMapper(factors=Ydf_DNN_TSNE['class'].unique(), \n",
    "                                       palette=palette)\n",
    "\n",
    "# create figure and plot\n",
    "p = bpl.figure(plot_width=1400, plot_height=1000)\n",
    "p.scatter(x='0', y='1',\n",
    "          color={'field': 'class', 'transform': color_map},\n",
    "          legend_label='class', source=source)\n",
    "p.title.text = \"DNN_TSNE\"\n",
    "bpl.show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def cluster2folder(clf, df, folder_name):\n",
    "    for c in pd.unique(clf['kmeans'].labels_):\n",
    "        d = os.path.join(folder_name, str(c))\n",
    "        if os.path.isdir(d):\n",
    "            shutil.rmtree(d)\n",
    "        os.mkdir(d)\n",
    "\n",
    "\n",
    "    for i in range(len(Ydf_DNN)):\n",
    "        f_src = os.path.join(path, 'Raw_data', df['id'][i])\n",
    "        f_tar = os.path.join(path, folder_name, str(df['class'][i]), df['id'][i])\n",
    "        #copyfile(f_src, f_tar)\n",
    "        os.symlink(f_src, f_tar)\n",
    "\n",
    "cluster2folder(clf_kmeans_DNN, Ydf_DNN, 'Results_DNN')\n",
    "cluster2folder(clf_kmeans_PCA, Ydf_PCA, 'Results_PCA')\n",
    "cluster2folder(clf_kmeans_DNN_TSNE, Ydf_DNN_TSNE, 'Results_DNN_TSNE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "name": "test.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
