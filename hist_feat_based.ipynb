{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import cv2\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keras\n",
    "from keras import Model\n",
    "from keras import regularizers, callbacks\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, UpSampling2D, Dense\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "raw_data_directory = os.path.join(path, 'Raw_data')\n",
    "list_filename = os.listdir(raw_data_directory)\n",
    "list_filename_full = [os.path.join(path, 'Raw_data', f) for f in list_filename]\n",
    "\n",
    "def extract_hist(f, scale_percent = 50):\n",
    "    \n",
    "    color = ('b','g','r')\n",
    "    im = cv2.imread(f)\n",
    "    width = int( np.shape(im)[1] * scale_percent / 100 )\n",
    "    height = int( np.shape(im)[0] * scale_percent / 100 )\n",
    "    normalization = float(width * height)\n",
    "    im = cv2.resize(im, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    hist_channel = [cv2.calcHist([im],[i],None,[hist_size],[0,hist_size]) for i, col in enumerate(color)]\n",
    "    hist = np.concatenate(hist_channel) / (np.max(hist_channel) + 0.001)\n",
    "    #hist = np.concatenate(hist_channel) / normalization\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "# options\n",
    "dataset = \"mnist\" # Chose either \"mnist\" or \"personal_data\" stored in Raw_data folder\n",
    "hist_data = 'compute' # Chose either \"compute\" to (re)compute histograms or \"load\" to load last personal_data\n",
    "hist_size = 256\n",
    "N_images = np.size(list_filename) # All images\n",
    "\n",
    "if dataset == \"mnist\":\n",
    "    (x_train, _), (x_test, _) = mnist.load_data()\n",
    "    \n",
    "    # Extract histogram for mnist\n",
    "    x_train = [cv2.calcHist([im], [0], None, [hist_size], [0,256]) / np.prod(im.shape) for im in x_train]\n",
    "    x_train = np.squeeze(np.array(x_train))\n",
    "    x_test = [cv2.calcHist([im], [0], None, [hist_size], [0,256]) / np.prod(im.shape) for im in x_test]\n",
    "    x_test = np.squeeze(np.array(x_test))\n",
    "    \n",
    "elif dataset == \"personal_data\":\n",
    "    if hist_data == 'compute':\n",
    "        # Compute histograms in parallel\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        hist = pool.starmap(extract_hist, [(f, 100) for f in list_filename_full[0:N_images]])\n",
    "        hist = np.squeeze(np.array(hist))\n",
    "        pool.close()\n",
    "\n",
    "        # Sauver ces histograms\n",
    "        np.save('histogram.npy', hist)\n",
    "\n",
    "    elif hist_data == 'load':\n",
    "        # Charger les histograms sauvegard√©s\n",
    "        hist = np.load('histogram.npy')\n",
    "        \n",
    "    x_train, x_test = train_test_split(hist, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim_red = 32\n",
    "dim_red_method = \"autoencoder\"\n",
    "\n",
    "if dim_red_method == \"pca\":\n",
    "    M = preprocessing.scale(hist)\n",
    "    Mp = pd.DataFrame(M, index=list_filename)\n",
    "\n",
    "    pca = PCA()\n",
    "    Y = pca.fit_transform(Mp)\n",
    "\n",
    "    print(pca.explained_variance_ratio_[0:20])\n",
    "\n",
    "elif dim_red_method == \"autoencoder\":\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "    input_vec = Input(shape= (x_train.shape[1],) )\n",
    "    \n",
    "    encoded = Dense(4*ndim_red, activation='relu')(input_vec)\n",
    "    encoded = Dense(2*ndim_red, activation='relu')(encoded)\n",
    "    \n",
    "    encoded = Dense(ndim_red, activation='relu')(encoded)\n",
    "    \n",
    "    decoded = Dense(2*ndim_red, activation='relu')(encoded)\n",
    "    decoded = Dense(4*ndim_red, activation='relu')(decoded)\n",
    "    decoded = Dense(x_train.shape[1], activation='sigmoid', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "    \n",
    "    autoencoder = Model(input_vec, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    # Encoder is needed to get only the encoded data\n",
    "    encoder = Model(input_vec, encoded)\n",
    "\n",
    "    # Decoder\n",
    "    input_decoder = Input(shape=(ndim_red), )\n",
    "    decoder_layer = Dense(x_train.shape[1], activation='sigmoid')(input_decoder)\n",
    "    decoder = Model(input_decoder, decoder_layer)\n",
    "\n",
    "    # Training on data\n",
    "    autoencoder.fit(x_train, x_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, x_test),\n",
    "                    callbacks=[early_stopping, TensorBoard(log_dir='./hist_based/')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing original histogram with decoded version.\n",
    "# Complete failure. Why histogram auto-encoding is so difficult ?\n",
    "\n",
    "sample = 3\n",
    "plt.plot(x_train[sample], color='r')\n",
    "\n",
    "enc_M0 = encoder.predict([x_train[sample:sample+1]])\n",
    "dec_M0 = decoder.predict(enc_M0)\n",
    "dec_M0 = dec_M0.reshape(x_train[sample].shape)\n",
    "dec_M0.shape\n",
    "plt.plot(dec_M0, color='b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
